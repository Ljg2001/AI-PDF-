import streamlit as st
from langchain.memory import ConversationBufferMemory
from utils import qa_agent, polish_paper

st.title("ğŸ“‘ AIæ™ºèƒ½PDFé—®ç­”+è®ºæ–‡æ¶¦è‰²å·¥å…·")

# æ·»åŠ åŠŸèƒ½é€‰æ‹©
mode = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½ï¼š", ["PDFé—®ç­”", "è®ºæ–‡æ¶¦è‰²"])

with st.sidebar:
    openai_api_key = st.text_input("è¯·è¾“å…¥OpenAI APIå¯†é’¥ï¼š", type="password")
    st.markdown("[è·å–OpenAI API key](https://platform.openai.com/account/api-keys)")
    base_url = st.text_input("è¯·è¾“å…¥Base URLï¼š", value="https://api.openai.com/v1")
    
    model_name = st.selectbox(
        "é€‰æ‹©æ¨¡å‹ï¼š",
        ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview", "gpt-4o-mini", "gpt-4o"],
        index=0
    )
    
    # ä¿®å¤æ¸©åº¦æ§åˆ¶æ»‘å—
    temperature = st.slider(
        "å›ç­”åˆ›é€ æ€§ï¼ˆæ¸©åº¦ï¼‰ï¼š",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1
    )

if mode == "PDFé—®ç­”":
    if "memory" not in st.session_state:
        st.session_state["memory"] = ConversationBufferMemory(
            return_messages=True,
            memory_key="chat_history",
            output_key="answer"
        )

    uploaded_file = st.file_uploader("ä¸Šä¼ ä½ çš„PDFæ–‡ä»¶ï¼š", type="pdf")
    
    # æ·»åŠ é¢„è®¾é—®é¢˜æ¨¡æ¿
    preset_questions = [
        "æ€»ç»“è¿™ç¯‡æ–‡ç« çš„ä¸»è¦å†…å®¹",
        "è¿™ç¯‡æ–‡ç« çš„åˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è¿™ç¯‡æ–‡ç« çš„ç ”ç©¶æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è¿™ç¯‡æ–‡ç« çš„å®éªŒç»“æœå¦‚ä½•ï¼Ÿ",
        "è‡ªå®šä¹‰é—®é¢˜"
    ]
    
    question_type = st.selectbox("é€‰æ‹©é—®é¢˜ç±»å‹ï¼š", preset_questions)
    if question_type == "è‡ªå®šä¹‰é—®é¢˜":
        question = st.text_input("è¾“å…¥ä½ çš„é—®é¢˜ï¼š", disabled=not uploaded_file)
    else:
        question = question_type

    if uploaded_file and question and not openai_api_key:
        st.info("è¯·è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥")

    if uploaded_file and question and openai_api_key:
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
            response = qa_agent(openai_api_key, base_url, st.session_state["memory"],
                              uploaded_file, question, model_name, temperature)
        st.write("### ç­”æ¡ˆ")
        st.write(response["answer"])
        st.session_state["chat_history"] = response["chat_history"]

        # æ·»åŠ ç­”æ¡ˆæ“ä½œæŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("å¤åˆ¶ç­”æ¡ˆ"):
                st.write("ç­”æ¡ˆå·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼")
                st.session_state['clipboard'] = response["answer"]
        with col2:
            if st.button("å¯¼å‡ºèŠå¤©è®°å½•"):
                st.download_button(
                    label="ä¸‹è½½èŠå¤©è®°å½•",
                    data=str(st.session_state["chat_history"]),
                    file_name="chat_history.txt"
                )

    if "chat_history" in st.session_state:
        with st.expander("å†å²æ¶ˆæ¯", expanded=False):
            for i in range(0, len(st.session_state["chat_history"]), 2):
                with st.chat_message("user"):
                    st.write(st.session_state["chat_history"][i].content)
                with st.chat_message("assistant"):
                    st.write(st.session_state["chat_history"][i+1].content)
                if i < len(st.session_state["chat_history"]) - 2:
                    st.divider()

else:  # è®ºæ–‡æ¶¦è‰²æ¨¡å¼
    st.write("### è®ºæ–‡æ¶¦è‰²")
    polish_type = st.selectbox(
        "é€‰æ‹©æ¶¦è‰²ç±»å‹ï¼š",
        ["å­¦æœ¯æ¶¦è‰²", "è¯­æ³•ä¿®æ”¹", "ç®€å•æ¶¦è‰²", "è‡ªå®šä¹‰æ¶¦è‰²"]
    )
    
    # æ·»åŠ ç¤ºä¾‹æ–‡æœ¬
    if st.checkbox("æŸ¥çœ‹ç¤ºä¾‹æ–‡æœ¬"):
        st.info("è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–‡æœ¬ï¼Œå±•ç¤ºäº†å¸¸è§çš„å­¦æœ¯å†™ä½œã€‚æ‚¨å¯ä»¥å‚è€ƒè¿™ä¸ªæ ¼å¼æ¥è¾“å…¥æ‚¨çš„æ–‡æœ¬ã€‚")
        st.write("""â€”This paper introduces a highly flexible, quantized,
                    memory-efficient, and ultra-lightweight object detection network,
                    called TinyissimoYOLO. It aims to enable object detection on
                    microcontrollers in the power domain of milliwatts, with less
                    than 05MB memory available for storing convolutional neural
                    network (CNN) weights. The proposed quantized network archi
                    tecture with 422k parameters, enables real-time object detection
                    on embedded microcontrollers, and it has been evaluated to
                    exploit CNN accelerators. In particular, the proposed network has
                    been deployed on the MAX78000 microcontroller achieving high
                    frame-rate of up to 180fps and an ultra-low energy consumption
                    of only 196 J per inference with an inference efficiency of more
                    than 106MAC/Cycle. TinyissimoYOLO can be trained for any
                    multi-object detection. However, considering the small network
                    size, adding object detection classes will increase the size and
                    memory consumption of the network, thus object detection
                    with up to 3 classes is demonstrated. Furthermore, the net
                    work is trained using quantization-aware training and deployed
                    with 8-bit quantization on different microcontrollers, such as
                    STM32H7A3, STM32L4R9, Apollo4b and on the MAX78000â€™s
                    CNN accelerator. Performance evaluations are presented in this
                    paper.""")
    
    # æ·»åŠ è‡ªå®šä¹‰æ¶¦è‰²è¦æ±‚
    custom_requirements = []
    if polish_type == "è‡ªå®šä¹‰æ¶¦è‰²":
        st.write("### è‡ªå®šä¹‰æ¶¦è‰²è¦æ±‚")
        st.info("æ‚¨å¯ä»¥æ·»åŠ æœ€å¤š5ä¸ªè‡ªå®šä¹‰è¦æ±‚")
        
        # é¢„è®¾ä¸€äº›å¸¸ç”¨è¦æ±‚ä¾›é€‰æ‹©
        preset_requirements = [
            "æé«˜å­¦æœ¯æ€§",
            "å¢åŠ ä¸“ä¸šæœ¯è¯­",
            "ç®€åŒ–è¡¨è¾¾",
            "æ”¹å–„è¯­æ³•",
            "å¢åŠ è¿è´¯æ€§",
            "è°ƒæ•´è¯­æ°”",
            "æ·»åŠ è¿‡æ¸¡å¥",
            "ä¼˜åŒ–æ®µè½ç»“æ„",
            "å¼ºè°ƒåˆ›æ–°ç‚¹",
            "å…¶ä»–"
        ]
        
        for i in range(5):
            col1, col2 = st.columns([3, 1])
            with col1:
                req = st.selectbox(
                    f"è¦æ±‚ {i+1}",
                    ["æ— "] + preset_requirements,
                    key=f"req_{i}"
                )
            if req == "å…¶ä»–":
                with col2:
                    req = st.text_input("è‡ªå®šä¹‰è¦æ±‚", key=f"custom_req_{i}")
            if req and req != "æ— ":
                custom_requirements.append(req)
    
    text_input = st.text_area("è¯·è¾“å…¥éœ€è¦æ¶¦è‰²çš„æ–‡æœ¬ï¼š", height=200)
    
    col1, col2 = st.columns(2)
    with col1:
        max_length = st.number_input("æœ€å¤§è¾“å‡ºé•¿åº¦", min_value=100, value=1000, step=100)
    with col2:
        language = st.selectbox("è¾“å‡ºè¯­è¨€", ["ä¸­æ–‡", "è‹±æ–‡", "ä¸­è‹±å¯¹ç…§"])
    
    if st.button("å¼€å§‹æ¶¦è‰²", type="primary") and text_input and openai_api_key:
        with st.spinner("AIæ­£åœ¨æ¶¦è‰²ä¸­ï¼Œè¯·ç¨ç­‰..."):
            polished_text = polish_paper(
                text_input, 
                polish_type, 
                model_name, 
                openai_api_key, 
                base_url,
                temperature,
                max_length,
                language,
                custom_requirements
            )
        st.write("### æ¶¦è‰²ç»“æœ")
        st.write(polished_text)
        
        # æ·»åŠ ç»“æœæ“ä½œæŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("å¤åˆ¶ç»“æœ"):
                st.write("ç»“æœå·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼")
                st.session_state['clipboard'] = polished_text
        with col2:
            st.download_button(
                label="å¯¼å‡ºç»“æœ",
                data=polished_text,
                file_name="polished_text.txt"
            )

# æ·»åŠ é¡µè„š
st.markdown("---")
st.markdown("Made with â¤ï¸ by lucky_é¹¿äºº")
